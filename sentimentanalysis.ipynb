{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "crNg4tQ3R61i",
    "outputId": "91a2ff4a-f007-4653-86f1-16ce22759a78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
      "Collecting vaderSentiment\n",
      "  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl.metadata (572 bytes)\n",
      "Requirement already satisfied: textblob in /usr/local/lib/python3.11/dist-packages (0.19.0)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.50.3)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from vaderSentiment) (2.32.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->vaderSentiment) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->vaderSentiment) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->vaderSentiment) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->vaderSentiment) (2025.1.31)\n",
      "Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.0/126.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m74.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, vaderSentiment, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 vaderSentiment-3.3.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas vaderSentiment textblob transformers torch nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WdqvLZYmRpLg",
    "outputId": "a1cd514d-fd30-462e-c668-c0e89932266d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use cuda:0\n",
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment analysis completed and saved in 'final_sentiment_analysis.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Install required libraries (uncomment if needed)\n",
    "# !pip install pandas vaderSentiment textblob transformers torch nltk\n",
    "\n",
    "import pandas as pd\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from textblob import TextBlob\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load dataset\n",
    "input_file = \"filtered_deepseek_english_data.csv\"  # Change to your file name\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# Drop rows with missing text values\n",
    "df.dropna(subset=[\"text\"], inplace=True)\n",
    "\n",
    "# Convert 'text' to string to avoid errors\n",
    "df[\"text\"] = df[\"text\"].astype(str).str.strip()\n",
    "\n",
    "# Initialize sentiment analysis models\n",
    "vader_analyzer = SentimentIntensityAnalyzer()\n",
    "bert_analyzer = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "# Function for VADER sentiment analysis\n",
    "def get_vader_score(text):\n",
    "    return vader_analyzer.polarity_scores(text)[\"compound\"]\n",
    "\n",
    "# Function for TextBlob sentiment analysis\n",
    "def get_textblob_score(text):\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "\n",
    "# Function for BERT sentiment analysis\n",
    "def get_bert_score(text):\n",
    "    text = text[:512]  # Limit text length to 512 tokens for BERT\n",
    "    if not text:  # Handle empty strings\n",
    "        return 0\n",
    "\n",
    "    result = bert_analyzer(text)\n",
    "    label = result[0][\"label\"].lower()\n",
    "    score = result[0][\"score\"]\n",
    "\n",
    "    return score if label == \"positive\" else -score if label == \"negative\" else 0\n",
    "\n",
    "# Apply sentiment analysis functions\n",
    "df[\"VADER Score\"] = df[\"text\"].apply(get_vader_score)\n",
    "df[\"TextBlob Score\"] = df[\"text\"].apply(get_textblob_score)\n",
    "df[\"BERT Score\"] = df[\"text\"].apply(get_bert_score)\n",
    "\n",
    "# Compute average sentiment score\n",
    "df[\"Average Sentiment\"] = df[[\"VADER Score\", \"TextBlob Score\", \"BERT Score\"]].mean(axis=1)\n",
    "\n",
    "# Keep only necessary columns\n",
    "df = df[[\"pseudo_id\", \"text\", \"VADER Score\", \"TextBlob Score\", \"BERT Score\", \"Average Sentiment\"]]\n",
    "\n",
    "# Save the results to a new CSV file\n",
    "output_file = \"final_sentiment_analysis.csv\"\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Sentiment analysis completed and saved in '{output_file}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sk8Fg_dgashQ",
    "outputId": "eeebf5ff-4b83-47f8-b2fa-2e406988dcae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment classification added and saved in 'final_sentiment_analysis_with_labels.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the existing sentiment analysis results\n",
    "input_file = \"final_sentiment_analysis.csv\"\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# Define function to classify sentiment based on the average score\n",
    "def classify_sentiment(score):\n",
    "    if score > 0.05:\n",
    "        return \"Positive\"\n",
    "    elif score < -0.05:\n",
    "        return \"Negative\"\n",
    "    else:\n",
    "        return \"Neutral\"\n",
    "\n",
    "# Apply classification\n",
    "df[\"Sentiment Label\"] = df[\"Average Sentiment\"].apply(classify_sentiment)\n",
    "\n",
    "# Save the updated CSV file\n",
    "output_file = \"final_sentiment_analysis_with_labels.csv\"\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Sentiment classification added and saved in '{output_file}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EzpkUOtubIJX",
    "outputId": "d601e2f1-61ab-40f4-c7e0-f889467deb15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment analysis with VADER and TextBlob completed. Results saved to 'sentiment_comparison.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Load dataset\n",
    "input_file = \"filtered_deepseek_english_data.csv\"  # Update with your file name\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# Initialize sentiment analyzer\n",
    "vader_analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "def get_vader_score(text):\n",
    "    return vader_analyzer.polarity_scores(text)[\"compound\"]\n",
    "\n",
    "def get_textblob_score(text):\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "\n",
    "# Apply sentiment analysis\n",
    "df[\"VADER Score\"] = df[\"text\"].astype(str).apply(get_vader_score)\n",
    "df[\"TextBlob Score\"] = df[\"text\"].astype(str).apply(get_textblob_score)\n",
    "\n",
    "# Compute average sentiment score\n",
    "df[\"Average Sentiment\"] = df[[\"VADER Score\", \"TextBlob Score\"]].mean(axis=1)\n",
    "\n",
    "# Function to classify sentiment labels\n",
    "def classify_sentiment(score):\n",
    "    if score > 0.05:\n",
    "        return \"Positive\"\n",
    "    elif score < -0.05:\n",
    "        return \"Negative\"\n",
    "    else:\n",
    "        return \"Neutral\"\n",
    "\n",
    "# Apply classification\n",
    "df[\"Sentiment Label\"] = df[\"Average Sentiment\"].apply(classify_sentiment)\n",
    "\n",
    "# Keep only relevant columns\n",
    "df = df[[\"pseudo_id\", \"text\", \"VADER Score\", \"TextBlob Score\", \"Average Sentiment\", \"Sentiment Label\"]]\n",
    "\n",
    "# Save results\n",
    "output_file = \"sentiment_comparison.csv\"\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Sentiment analysis with VADER and TextBlob completed. Results saved to '{output_file}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8c3IoQaddBf6",
    "outputId": "78ead6e3-e585-47d7-94c8-0ec603b3d605"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison completed and saved in 'sentiment_comparison_with_labels_match.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the two CSV files\n",
    "final_sentiment_file = \"final_sentiment_analysis_with_labels.csv\"\n",
    "comparison_file = \"sentiment_comparison.csv\"\n",
    "\n",
    "df_final = pd.read_csv(final_sentiment_file)\n",
    "df_comparison = pd.read_csv(comparison_file)\n",
    "\n",
    "# Merge datasets on 'pseudo_id'\n",
    "merged_df = df_final.merge(df_comparison, on=\"pseudo_id\", suffixes=(\"_Final\", \"_V&T\"))\n",
    "\n",
    "# Keep relevant columns\n",
    "merged_df = merged_df[\n",
    "    [\n",
    "        \"pseudo_id\",\n",
    "        \"text_Final\",\n",
    "        \"VADER Score_Final\", \"TextBlob Score_Final\", \"BERT Score\", \"Sentiment Label_Final\",\n",
    "        \"VADER Score_V&T\", \"TextBlob Score_V&T\", \"Sentiment Label_V&T\"\n",
    "    ]\n",
    "]\n",
    "\n",
    "# Rename for clarity\n",
    "merged_df.rename(columns={\"text_Final\": \"text\"}, inplace=True)\n",
    "\n",
    "# Add column to compare sentiment labels\n",
    "merged_df[\"Labels Match\"] = merged_df.apply(\n",
    "    lambda row: \"Match\" if row[\"Sentiment Label_Final\"] == row[\"Sentiment Label_V&T\"] else \"Different\", axis=1\n",
    ")\n",
    "\n",
    "# Save comparison results\n",
    "output_file = \"sentiment_comparison_with_labels_match.csv\"\n",
    "merged_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Comparison completed and saved in '{output_file}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IBWx4h50oc14",
    "outputId": "1bb0914e-a7e3-4933-93c8-2801b9c2556b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "<ipython-input-3-e846559262bb>:34: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.countplot(data=df, x=\"Sentiment Label\", order=[\"Positive\", \"Neutral\", \"Negative\"], palette=\"pastel\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ DOCX report saved as 'Sentiment_Analysis_Report.docx'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from docx import Document\n",
    "from docx.shared import Inches\n",
    "import nltk\n",
    "import os\n",
    "\n",
    "# Download stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# --- Setup ---\n",
    "input_csv = \"final_sentiment_analysis_with_labels.csv\"\n",
    "output_dir = \"sentiment_report_visuals\"\n",
    "report_file = \"Sentiment_Analysis_Report.docx\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(input_csv)\n",
    "\n",
    "# Count sentiment classes\n",
    "sentiment_counts = df[\"Sentiment Label\"].value_counts()\n",
    "total = len(df)\n",
    "positive_count = sentiment_counts.get(\"Positive\", 0)\n",
    "neutral_count = sentiment_counts.get(\"Neutral\", 0)\n",
    "negative_count = sentiment_counts.get(\"Negative\", 0)\n",
    "dominant_sentiment = sentiment_counts.idxmax()\n",
    "\n",
    "# --- Generate Bar Chart ---\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.countplot(data=df, x=\"Sentiment Label\", order=[\"Positive\", \"Neutral\", \"Negative\"], palette=\"pastel\")\n",
    "plt.title(\"Sentiment Distribution (Bar Chart)\")\n",
    "plt.xlabel(\"Sentiment\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.tight_layout()\n",
    "bar_chart_path = f\"{output_dir}/sentiment_bar_chart.png\"\n",
    "plt.savefig(bar_chart_path)\n",
    "plt.close()\n",
    "\n",
    "# --- Generate Pie Chart ---\n",
    "colors = [\"#8fd694\", \"#f7d794\", \"#ff6b6b\"]\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.pie(sentiment_counts, labels=sentiment_counts.index, autopct=\"%1.1f%%\", startangle=140, colors=colors)\n",
    "plt.axis(\"equal\")\n",
    "plt.title(\"Sentiment Distribution (Pie Chart)\")\n",
    "pie_chart_path = f\"{output_dir}/sentiment_pie_chart.png\"\n",
    "plt.savefig(pie_chart_path)\n",
    "plt.close()\n",
    "\n",
    "# --- Generate Word Clouds ---\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "def generate_wordcloud(sentiment_label, color_map):\n",
    "    text_data = \" \".join(df[df[\"Sentiment Label\"] == sentiment_label][\"text\"].dropna().astype(str))\n",
    "    wordcloud = WordCloud(\n",
    "        width=800,\n",
    "        height=400,\n",
    "        background_color=\"white\",\n",
    "        stopwords=STOPWORDS.union(stop_words),\n",
    "        colormap=color_map\n",
    "    ).generate(text_data)\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(f\"Word Cloud - {sentiment_label}\")\n",
    "    cloud_path = f\"{output_dir}/wordcloud_{sentiment_label.lower()}.png\"\n",
    "    plt.savefig(cloud_path)\n",
    "    plt.close()\n",
    "    return cloud_path\n",
    "\n",
    "positive_wc = generate_wordcloud(\"Positive\", \"Greens\")\n",
    "neutral_wc = generate_wordcloud(\"Neutral\", \"Blues\")\n",
    "negative_wc = generate_wordcloud(\"Negative\", \"Reds\")\n",
    "\n",
    "# --- Create DOCX Report ---\n",
    "doc = Document()\n",
    "doc.add_heading(\"Sentiment Analysis Report\", 0)\n",
    "\n",
    "# Overview\n",
    "doc.add_heading(\"Overview\", level=1)\n",
    "doc.add_paragraph(\n",
    "    f\"This report summarizes sentiment analysis results from the file '{input_csv}', \"\n",
    "    f\"which includes {total} text entries. Sentiment labels were generated using VADER, \"\n",
    "    f\"TextBlob, and BERT scores. The final label is based on the average sentiment score.\"\n",
    ")\n",
    "\n",
    "# Distribution Charts\n",
    "doc.add_heading(\"Sentiment Distribution\", level=1)\n",
    "doc.add_picture(bar_chart_path, width=Inches(5.5))\n",
    "doc.add_paragraph(\"Bar chart showing the count of Positive, Neutral, and Negative sentiments.\")\n",
    "\n",
    "doc.add_picture(pie_chart_path, width=Inches(5.5))\n",
    "doc.add_paragraph(\"Pie chart showing sentiment proportions.\")\n",
    "\n",
    "# Word Clouds\n",
    "doc.add_heading(\"Word Clouds\", level=1)\n",
    "\n",
    "doc.add_paragraph(\"Word Cloud - Positive\")\n",
    "doc.add_picture(positive_wc, width=Inches(5.5))\n",
    "\n",
    "doc.add_paragraph(\"Word Cloud - Neutral\")\n",
    "doc.add_picture(neutral_wc, width=Inches(5.5))\n",
    "\n",
    "doc.add_paragraph(\"Word Cloud - Negative\")\n",
    "doc.add_picture(negative_wc, width=Inches(5.5))\n",
    "\n",
    "# Observations\n",
    "doc.add_heading(\"Key Observations\", level=1)\n",
    "doc.add_paragraph(f\"• Most of the texts were classified as **{dominant_sentiment}**.\")\n",
    "doc.add_paragraph(f\"• Positive: {positive_count}\")\n",
    "doc.add_paragraph(f\"• Neutral: {neutral_count}\")\n",
    "doc.add_paragraph(f\"• Negative: {negative_count}\")\n",
    "doc.add_paragraph(\"• The combination of three sentiment models ensures a more reliable classification.\")\n",
    "\n",
    "# Save Report\n",
    "doc.save(report_file)\n",
    "print(f\"✅ DOCX report saved as '{report_file}'\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "state": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
